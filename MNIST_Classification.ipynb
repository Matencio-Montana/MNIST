{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d484bb-ab08-46df-99af-205d3da67da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9003c4-8ca5-4eed-818f-cbd08f7ef8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42 for all relevant libraries.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os # To set environment variables, useful for some libraries\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the random seed for reproducibility across different libraries.\n",
    "    \"\"\"\n",
    "    # 1. Set seed for Python's built-in random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # 2. Set seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 3. Set seed for PyTorch (CPU and GPU)\n",
    "    torch.manual_seed(seed) # For CPU operations\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed) # For current GPU\n",
    "        torch.cuda.manual_seed_all(seed) # For all GPUs (if you have multiple)\n",
    "\n",
    "    # 4. Ensure deterministic behavior for CuDNN (GPU operations)\n",
    "    #    This can sometimes slightly slow down training, but ensures exact reproducibility.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # Disable CuDNN auto-tuner for deterministic ops\n",
    "\n",
    "    # 5. Set environment variable for Python hashing (affects dicts, sets, etc.)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to {seed} for all relevant libraries.\")\n",
    "\n",
    "MY_RANDOM_SEED = 42\n",
    "set_seed(MY_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea04d974-9ece-4093-b335-224372d969ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243679ef-bcf7-49c6-9e6e-363620c3c1ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc53a8d-4d1d-4457-8d45-ff54f5195dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "for X,y in training_dataloader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4e09beb-7116-4fb9-8847-ed8ef8e34c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_size, images_size, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels,hidden_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1) ),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_channels * images_size[0]//2 * images_size[1]//2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d10934-0e41-40c3-b4d6-9303ac2edd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "hidden_channels = 32\n",
    "output_size = 10\n",
    "images_size = (28,28)\n",
    "dropout_prob = 0.3\n",
    "\n",
    "model_CNN = MNIST_CNN(input_channels, hidden_channels, output_size, images_size, dropout_prob).to(device)\n",
    "criterion_CNN = nn.CrossEntropyLoss() # We use CrossEntropyLoss as we are solving a classification problem\n",
    "optimizer_CNN = torch.optim.AdamW(model_CNN.parameters(), lr=0.0001, weight_decay=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "254446ca-7373-4adb-a16a-5dd415a66785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(dataloader,model,criterion, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    total_samples_processed_in_epoch = 0 #Initialize a variable to track the total samples processed in this epoch\n",
    "    model.train()\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred=model(X)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() #update of weights and biases  \n",
    "        optimizer.zero_grad() #gradient reset \n",
    "\n",
    "        #Accumulate the number of samples processed in the current batch\n",
    "        total_samples_processed_in_epoch += len(X) \n",
    "\n",
    "\n",
    "        if batch%100==0:\n",
    "            loss_val = loss.item()\n",
    "            print(f\"loss: {loss_val:>7f}  [{total_samples_processed_in_epoch:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    elements_per_batch = len(dataloader)\n",
    "    model.eval()\n",
    "    sum_loss_per_batch, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            sum_loss_per_batch+=criterion(pred,y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    sum_loss_per_batch/=elements_per_batch\n",
    "    correct/=size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {sum_loss_per_batch:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "671e8e17-35e7-441a-9ee1-25920ebe905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.082898  [  128/60000]\n",
      "loss: 0.130018  [12928/60000]\n",
      "loss: 0.126484  [25728/60000]\n",
      "loss: 0.083000  [38528/60000]\n",
      "loss: 0.161801  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.106428 \n",
      "\n",
      "Current Learning Rate: 0.000091\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.130855  [  128/60000]\n",
      "loss: 0.123612  [12928/60000]\n",
      "loss: 0.046557  [25728/60000]\n",
      "loss: 0.092584  [38528/60000]\n",
      "loss: 0.078742  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.094638 \n",
      "\n",
      "Current Learning Rate: 0.000068\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.066172  [  128/60000]\n",
      "loss: 0.145414  [12928/60000]\n",
      "loss: 0.140044  [25728/60000]\n",
      "loss: 0.109267  [38528/60000]\n",
      "loss: 0.072652  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.085248 \n",
      "\n",
      "Current Learning Rate: 0.000041\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.035366  [  128/60000]\n",
      "loss: 0.047261  [12928/60000]\n",
      "loss: 0.045005  [25728/60000]\n",
      "loss: 0.090875  [38528/60000]\n",
      "loss: 0.054712  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.082703 \n",
      "\n",
      "Current Learning Rate: 0.000019\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.025748  [  128/60000]\n",
      "loss: 0.073273  [12928/60000]\n",
      "loss: 0.093037  [25728/60000]\n",
      "loss: 0.134482  [38528/60000]\n",
      "loss: 0.073937  [51328/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.079855 \n",
      "\n",
      "Current Learning Rate: 0.000010\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "scheduler_CNN = lr_scheduler.CosineAnnealingLR(optimizer_CNN, T_max=epochs, eta_min=1e-5)\n",
    "for iteration in range(epochs):\n",
    "    print(f\"Epoch {iteration+1}\\n-------------------------------\")\n",
    "    training_loop(training_dataloader,model_CNN,criterion_CNN,optimizer_CNN)\n",
    "    test_loop(test_dataloader,model_CNN,criterion_CNN)\n",
    "    scheduler_CNN.step()\n",
    "    #display the current learning rate \n",
    "    current_lr = optimizer_CNN.param_groups[0]['lr']\n",
    "    print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
